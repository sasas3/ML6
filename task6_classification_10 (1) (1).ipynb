{"cells":[{"cell_type":"markdown","metadata":{"id":"r-Mb7bnoaRLM"},"source":["# Логичтическая регрессия, метод опорных векторов, one-hot кодирование"]},{"cell_type":"markdown","metadata":{"id":"pNyXo3CvaRLP"},"source":["### О задании\n","\n","В этом задании вы изучите методы работы с категориальными переменными"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ndj090dOaRLQ","outputId":"a92ec05e-953b-454a-990f-3f865a27d461","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734335767030,"user_tz":-180,"elapsed":378,"user":{"displayName":"Александр Сайгаков","userId":"17993697933644502404"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Populating the interactive namespace from numpy and matplotlib\n"]}],"source":["%pylab inline\n","import pandas as pd\n","\n","from sklearn.base import BaseEstimator\n","from sklearn.datasets import load_diabetes\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"1_wS0x7RaRLR"},"source":["__Задание 1.__ Обучение логистической регрессии на реальных данных и оценка качества классификации.\n","\n","**(2 балла)**\n"]},{"cell_type":"markdown","metadata":{"id":"94eHa5RgaRLS"},"source":["Загрузим данные с конкурса [Kaggle Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) (вам нужна только обучающая выборка). Задача состоит в определении водителей, которые в ближайший год воспользуются своей автомобильной страховкой (бинарная классификация). Но для нас важна будет не сама задача, а только её данные. При этом под нужды задания мы немного модифицируем датасет."]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"id":"BJQn-94DaRLS","executionInfo":{"status":"ok","timestamp":1734335807415,"user_tz":-180,"elapsed":3385,"user":{"displayName":"Александр Сайгаков","userId":"17993697933644502404"}}},"outputs":[],"source":["import pandas as pd\n","data = pd.read_csv('/train.csv', index_col=0)\n","target = data.target.values\n","data = data.drop('target', axis=1)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xeTkzzbld7A-","executionInfo":{"status":"ok","timestamp":1734335850974,"user_tz":-180,"elapsed":19423,"user":{"displayName":"Александр Сайгаков","userId":"17993697933644502404"}},"outputId":"0af5910b-c745-4c32-90e8-86c0f981950e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"u2Su7GNhaRLT"},"source":["Пересемплируем выборку так, чтобы положительных и отрицательных объектов в выборке было одинаковое число. Разделим на обучающую и тестовую выборки."]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"id":"fot9A7L8aRLT","executionInfo":{"status":"ok","timestamp":1734335854893,"user_tz":-180,"elapsed":541,"user":{"displayName":"Александр Сайгаков","userId":"17993697933644502404"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","np.random.seed(910)\n","mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n","mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n","\n","data = pd.concat((data.iloc[mask_plus], data.iloc[mask_zero]))\n","target = np.hstack((target[mask_plus], target[mask_zero]))\n","\n","X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5)"]},{"cell_type":"markdown","metadata":{"id":"6GB0kVSoaRLT"},"source":["Не забудьте отнормировать признаки (можно воспользоваться StandardScaler или сделать это вручную). Пока не будем обращать внимание на то, что некоторые признаки категориальные (этим мы займёмся позже)."]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"id":"5dDctZhDaRLU","executionInfo":{"status":"ok","timestamp":1734335919919,"user_tz":-180,"elapsed":1036,"user":{"displayName":"Александр Сайгаков","userId":"17993697933644502404"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"mSrjeimpaRLU"},"source":["Обучите логистическую регрессию с удобными для вас параметрами, примените регуляризацию, найдтие оптимум. Сделайте предсказание на тестовой части выборки. Замерьте качество."]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":true,"id":"A1tEHyNFaRLU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734337019891,"user_tz":-180,"elapsed":1885,"user":{"displayName":"Александр Сайгаков","userId":"17993697933644502404"}},"outputId":"044df921-e80d-4749-bbfa-2ba141b812ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the model: 0.58785\n","Precision of the model: 0.5952995251826637\n","Recall of the model: 0.5490741111066672\n","F1 score of the model: 0.5712532118299368\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","model = LogisticRegression(max_iter=1000)\n","model = model.fit(X_train, y_train)\n","predictions = model.predict(X_test)\n","\n","acc = accuracy_score(y_test, predictions)\n","prec = precision_score(y_test, predictions)\n","rec = recall_score(y_test, predictions)\n","f1_metric = f1_score(y_test, predictions)\n","print(f\"Accuracy of the model:\", acc)\n","print(f\"Precision of the model:\", prec)\n","print(f\"Recall of the model:\", rec)\n","print(f\"F1 score of the model:\", f1_metric)"]},{"cell_type":"markdown","metadata":{"id":"N9UQ31XFaRLU"},"source":["__Выводы__ в свободной форме:"]},{"cell_type":"markdown","source":["Мы получили довольно средний скор. Это случилось из-за того, что мы ничего не делали с категориальными признаками и использовали дефолт регуляризатор"],"metadata":{"id":"IGof5Hokeqyx"}},{"cell_type":"markdown","metadata":{"id":"rTUVvmreaRLV"},"source":["__Задание 2.__ Изучение влияния регуляризатора на процесс обучения\n","\n","__(2 балла)__\n","\n","Проверьте на практике, как влияет регуляризатор на процесс обучения (убывание функции потерь на обучающей и отложенной выборках). Чтобы считать функцию потерь на отложенной выборке после каждой итерации, запускайте процесс обучения логистической регрессии с параметром $max\\_iter=1$ и $w^{(0)}$, полученным на предыдущей итерации. Постройте два графика: на одном из них логистическая регрессия с коэффициентом регуляризации, равным 0, а на другом с некоторым разумным значением. На каждом графике одновременно должна быть и функция потерь для обучающей, и для тестовой выборки. Не забудьте сделать одинаковыми оси обоих графиков. Какие выводы вы можете сделать?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4YkmjpIaRLV"},"outputs":[],"source":["# Your code here\n","# ..."]},{"cell_type":"markdown","metadata":{"id":"SP-lz7NxaRLV"},"source":["__Выводы:__"]},{"cell_type":"markdown","metadata":{"id":"lHvrjAQnaRLW"},"source":["## Часть 2. Работа с категориальными переменными"]},{"cell_type":"markdown","metadata":{"id":"_doKeEKxaRLW"},"source":["В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n","- One-hot-кодирование\n","- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n","\n","Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n","$$\n","b_i(x) = [f_j(x) = c_i]\n","$$\n","\n","__Задание 1.__ Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было ранее). Измерьте время, потребовавшееся на обучение модели.\n","\n","__(3 балла)__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GC4tPzPbaRLW"},"outputs":[],"source":["# Your code here\n","# ..."]},{"cell_type":"markdown","metadata":{"id":"izITXcOWaRLW"},"source":["Как можно было заменить, one-hot-кодирование может сильно увеличивать количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирование категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n","$$\n","g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n","$$\n","\n","__Задание 2.__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущим экспериментов. Заметили ли вы что-то интересное?\n","\n","__(2 балла)__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJmhJjcyaRLW"},"outputs":[],"source":["# Your code here\n","# ..."]},{"cell_type":"markdown","metadata":{"id":"CZ6BybtVaRLW"},"source":["__Вывод:__"]},{"cell_type":"markdown","metadata":{"id":"IUSCGlbhaRLW"},"source":["Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n","- вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени)\n","- вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации)\n","- внесение некоторого шума в посчитанные признаки (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков).\n","\n","__Задание 3.__ Реализуйте корректное вычисление счётчиков двумя из трех вышеперчисленных способов, сравните. Снова обучите логистическую регрессию, оцените качество. Сделайте выводы.\n","\n","__(3 балла)__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YX9gBIEJaRLW"},"outputs":[],"source":["# Your code here\n","# ..."]},{"cell_type":"markdown","metadata":{"id":"CIXbvzlWaRLX"},"source":["__Вывод:__"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}